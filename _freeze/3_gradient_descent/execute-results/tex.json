{
  "hash": "5c857f9a3625a5e7100be586ad512da5",
  "result": {
    "markdown": "# Anatomía de un algoritmo de aprendizaje\n\n## Bloques de construcción de un algoritmo de aprendizaje\n\nEn los algoritmos de aprendizaje que abarcamos en la sección anterior podemos observar los 3 bloques que se utilizan para construirlos:\n\n+---------------------------+---------------------------------------------------------------------------------------------------+\n| Bloque                    | Descripción                                                                                       |\n+===========================+===================================================================================================+\n| Función de pérdida        | - Método para evaluar que tan bien se ajusta  el modelo a los datos de entrenamiento              |\n|                           | - Si el modelo no predice adecuadamente, la función de pérdida da un resultado mayor              |\n+---------------------------+---------------------------------------------------------------------------------------------------+\n| Criterio de optimización  | - Debe estar basado en la función de pérdida                                                      |\n+---------------------------+---------------------------------------------------------------------------------------------------+\n| Rutina de optimización    | - Utiliza los valores de la función objetivo y los datos para ajustar los parámetros del modelo   |\n+---------------------------+---------------------------------------------------------------------------------------------------+\n\n: Bloques de un algoritmo de aprendizaje.\n\n## Descenso de gradiente (GD)\n\nEl *descenso de gradiente* es un algoritmo iterativo que permite encontrar el máximo o mínimo de una función dada, y se utiliza en los algoritmos de *machine learning (ML)* y *deep learning (DL)* para minimizar las funiciones de pérdida.\n\nEn conjunto con el *descenso de gradiente estocástico*, son de los algoritmos más utilizados en *ML* y *DL*.\n\n### Requisitos de la función a optimizar\n\n- **Diferenciable:** tiene una derivada para cada punto en su dominio.\n\n![Funciones diferenciables](figuras/gd/dif.png){fig-alt=\"Funciones diferenciables.\" fig-align=\"left\"}\n\n![Funciones no diferenciables](figuras/gd/nodif.png){fig-alt=\"Funciones no diferenciables.\" fig-align=\"left\"}\n\n- **Convexa:** para una función univariada, una línea que conecta dos puntos de la función pasa sobre o encima de la función. Las funciones convexas solo tienen un mínimo, que es el mínimo global.\n\n![Funciones convexas](figuras/gd/convexa.png){fig-alt=\"Funciones convexas.\" fig-align=\"left\"}\n\nLos criterios de optimización de muchos modelos (regresión lineal y logística, SVM, entre otros) son convexos, por lo que el *GD* es un método adecuado.\n\nLos criterios de optimización para las redes neuronales no son convexos (tienen mínimos locales y globales), pero en la práctica es suficiente encontrar mínimos globales, por lo que el *GD* también resulta un método útil.\n\n### Gradiente\n\nEs la **pendiente** de una curva en una dirección específica.\n\nEn funciones univariadas la obtenemos evaluando la primera derivada en un punto de interés.\n\nEn funciones multivariadas, es un vector de derivadas en cada dirección principal, lo que conocemos como **derivadas parciales**.\n\nEl gradiente para una función $f(x)$ en un punto $p$ está dado por:\n$$\n\\nabla f(p) = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} (p) \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n} (p) \\end{bmatrix}\n$$\n\n### Algoritmo de descenso de gradiente\n\nEl método se puede resumir mediante la siguiente ecuación:\n\n$$\np_{n+1} = p_n - \\alpha \\nabla f(p_n)\n$$\n\n**Paso a paso:**\n\n1. Escoger un punto inicial: $p_n$\n\n2. Calcular el gradiente en este punto: $\\nabla f(p_n)$\n\n3. Moverse en la dirección contraria al gradiente, a una distancia dada por la tasa de aprendizaje $\\alpha$\n\n4. Repetir pasos 2 y 3 hasta que se cumpla lo siguiente:\n\n- Número máximo de iteraciones alcanzado\n\n- El tamaño del paso es más pequeño que la tolerancia definida (cambio en $\\alpha$ o gradiente muy baja)\n\n### Imports\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom typing import Callable\n```\n:::\n\n\n### Ejemplo 1: función univariada, derivable no convexa\n\n**Función a optimizar:**\n\\begin{equation*}\nf(x) = x^4 - 2x^3 + 2\n\\end{equation*}\nY su gradiente:\n\n\\begin{equation*}\n\\frac{df(x)}{dx} = 4x^3-6x^2\n\\end{equation*}\n\n**Definiendo $f(x)$ y $\\frac{df(x)}{dx}$ en python**\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# f(x)\ndef f_ej1(x:float):\n  return x**4-2*x**3+2\n\n# df(x)/dx\ndef dfdx_ej1(x:float):\n  return 4*x**3-6*x**2\n```\n:::\n\n\n### Gráfica de $f(x)$\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nx = np.linspace(-0.8, 2.2, 100)\ny = f_ej1(x)\nplt.grid(True)\n\nplt.plot(x,y)\n```\n\n::: {.cell-output .cell-output-display}\n![](3_gradient_descent_files/figure-pdf/cell-4-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n**Definiendo algoritmo `gradient_descent`**\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndef gradient_descent(start: float, gradient: Callable[[float], float],\n                     learn_rate: float, max_iter: int, tol: float = 0.01):\n    x = start\n    steps = [start]  # history tracking\n\n    for _ in range(max_iter):\n        diff = learn_rate*gradient(x)\n        if np.abs(diff) < tol:\n            break\n        x = x - diff\n        steps.append(x)  # history tracing\n  \n    return steps, x\n```\n:::\n\n\n**Llamando a `gradient_descent` para el ejemplo 1**\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nstart = 2\ngradient = dfdx_ej1\nlearn_rate = 0.1\nmax_iter = 100\n\ngradient_descent(start, gradient, learn_rate, max_iter)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n([2, 1.2, 1.3728000000000002, 1.4686874222592001, 1.4957044497076786],\n 1.4957044497076786)\n```\n:::\n:::\n\n\n::: {.content-visible when-format=\"html\"}\n![Animación del ejemplo 1.](figuras/gd/ej1-1.gif){#fig-ej1-1}\n:::\n\n**Variaciones al ejemplo 1**\n\n::: {.content-visible when-format=\"html\"}\n![Animación del ejemplo 1 (variación 1).](figuras/gd/ej1-2.gif){#fig-ej1-2}\n:::\n\n::: {.content-visible when-format=\"html\"}\n![Animación del ejemplo 1 (variación 2).](figuras/gd/ej1-3.gif){#fig-ej1-3}\n:::\n\n::: {.content-visible when-format=\"html\"}\n![Animación del ejemplo 1 (variación 3).](figuras/gd/ej1-4.gif){#fig-ej1-4}\n:::\n\n### Códigos usados para esta sección\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Gradient Descent\n# gcorazzari\n\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport numpy as np\n\nfrom typing import Callable\n\n\ndef update(frame):\n    x = x_gd[:frame]\n    y = y_gd[:frame]\n    line_gd.set_xdata(x)\n    line_gd.set_ydata(y)\n    return line_gd\n\n\ndef gradient_descent(\n    start: float,\n    gradient: Callable[[float], float],\n    learn_rate: float,\n    max_iter: int,\n    tol: float = 0.01,\n):\n    x = start\n    steps = [start]  # history tracking\n\n    for _ in range(max_iter):\n        diff = learn_rate * gradient(x)\n        if np.abs(diff) < tol:\n            break\n        x = x - diff\n        steps.append(x)  # history tracing\n\n    return steps, x\n\n\n# EJ1-4\ndef f_ej1(x: float):\n    return x**4 - 2 * x**3 + 2\n\n\ndef dfdx_ej1(x: float):\n    return 4 * x**3 - 6 * x**2\n\n\nstart = -0.5\ngradient = dfdx_ej1\nlearn_rate = 0.3\nmax_iter = 100\n\nres_ej1 = gradient_descent(start, gradient, learn_rate, max_iter)\n\nfig, ax = plt.subplots()\n\nx = np.linspace(-0.8, 2.2, 100)\ny = f_ej1(x)\n\nline = ax.plot(x, y)\n\nx_gd = np.array(res_ej1[0])\ny_gd = f_ej1(x_gd)\n\nline_gd = ax.plot(\n    res_ej1[0][0], f_ej1(res_ej1[0][0]), \"ro-\", linewidth=0.5, markersize=2\n)[0]\n\nani = animation.FuncAnimation(fig=fig, func=update, frames=102, interval=200)\n\nplt.grid(True)\nplt.title(\"Inicio=-0.5, alpha=0.3\")\n\nwriter = animation.PillowWriter(fps=5)\n\nplt.show()\nani.save(\"ej1-4.gif\", writer=writer)\n\n\n# EJ1-3\ndef f_ej1(x: float):\n    return x**4 - 2 * x**3 + 2\n\n\ndef dfdx_ej1(x: float):\n    return 4 * x**3 - 6 * x**2\n\n\nstart = -0.5\ngradient = dfdx_ej1\nlearn_rate = 0.1\nmax_iter = 100\n\nres_ej1 = gradient_descent(start, gradient, learn_rate, max_iter)\n\nfig, ax = plt.subplots()\n\nx = np.linspace(-0.8, 2.2, 100)\ny = f_ej1(x)\n\nline = ax.plot(x, y)\n\nx_gd = np.array(res_ej1[0])\ny_gd = f_ej1(x_gd)\n\nline_gd = ax.plot(\n    res_ej1[0][0], f_ej1(res_ej1[0][0]), \"ro-\", linewidth=0.5, markersize=2\n)[0]\n\nani = animation.FuncAnimation(fig=fig, func=update, frames=9, interval=500)\n\nplt.grid(True)\nplt.title(\"Inicio=-0.5, alpha=0.1\")\n\nwriter = animation.PillowWriter(fps=5)\n\nplt.show()\nani.save(\"ej1-3.gif\", writer=writer)\n\n\n# EJ1-2\ndef f_ej1(x: float):\n    return x**4 - 2 * x**3 + 2\n\n\ndef dfdx_ej1(x: float):\n    return 4 * x**3 - 6 * x**2\n\n\nstart = 2\ngradient = dfdx_ej1\nlearn_rate = 0.3\nmax_iter = 100\n\nres_ej1 = gradient_descent(start, gradient, learn_rate, max_iter)\n\nfig, ax = plt.subplots()\n\nx = np.linspace(-0.8, 2.2, 100)\ny = f_ej1(x)\n\nline = ax.plot(x, y)\n\nx_gd = np.array(res_ej1[0])\ny_gd = f_ej1(x_gd)\n\nline_gd = ax.plot(\n    res_ej1[0][0], f_ej1(res_ej1[0][0]), \"ro-\", linewidth=0.5, markersize=2\n)[0]\n\nani = animation.FuncAnimation(fig=fig, func=update, frames=4, interval=200)\n\nplt.grid(True)\nplt.title(\"Inicio=2, alpha=0.3\")\n\nwriter = animation.PillowWriter(fps=5)\n\nplt.show()\nani.save(\"ej1-2.gif\", writer=writer)\n\n\n# EJ1-1\ndef f_ej1(x: float):\n    return x**4 - 2 * x**3 + 2\n\n\ndef dfdx_ej1(x: float):\n    return 4 * x**3 - 6 * x**2\n\n\nstart = 2\ngradient = dfdx_ej1\nlearn_rate = 0.1\nmax_iter = 100\n\nres_ej1 = gradient_descent(start, gradient, learn_rate, max_iter)\n\nfig, ax = plt.subplots()\n\nx = np.linspace(-0.8, 2.2, 100)\ny = f_ej1(x)\n\nline = ax.plot(x, y)\n\nx_gd = np.array(res_ej1[0])\ny_gd = f_ej1(x_gd)\n\nline_gd = ax.plot(\n    res_ej1[0][0], f_ej1(res_ej1[0][0]), \"ro-\", linewidth=0.5, markersize=2\n)[0]\n\nani = animation.FuncAnimation(fig=fig, func=update, frames=6, interval=500)\n\nplt.grid(True)\nplt.title(\"Inicio=2, alpha=0.1\")\n\nwriter = animation.PillowWriter(fps=5)\n\nplt.show()\nani.save(\"ej1-1.gif\", writer=writer)\n```\n:::\n\n\n",
    "supporting": [
      "3_gradient_descent_files/figure-pdf"
    ],
    "filters": []
  }
}