{
  "hash": "d9fec80a917e75d619cca8517d9250db",
  "result": {
    "engine": "jupyter",
    "markdown": "# Práctica avanzada \n\n## Manejo de datos desbalanceados \n\nEl desbalance de clases en los conjuntos de datos es un desafío común en el aprendizaje automático, particularmente en aplicaciones como la detección de fraude, donde las clases de interés suelen estar subrepresentadas. Este desbalance puede sesgar el rendimiento de los modelos hacia la clase mayoritaria, resultando en una pobre clasificación de las instancias de la clase minoritaria.\n\n###  Solución mediante Pesos Diferenciales en SVM\n\nEl SVM (Support Vector Machine) con margen blando permite manejar el desbalance mediante la asignación de un costo diferente a las clasificaciones erróneas de las clases. Matemáticamente, esto se refleja en la función de pérdida, donde el costo CC se ajusta por clase:\n\n\\begin{equation*}\nL(y,f(x))=C_{clase}⋅max⁡(0,1−y⋅f(x))2\n\\end{equation*}\n\ndonde \\(C_{clase}\\) es el peso asignado a la clase, \\(y\\) es la etiqueta verdadera, y \\(f(x)\\) es la decisión del modelo.\n\n#### Implementación\nVeamos cómo implementar un clasificador SVM que gestiona el desbalance de clases asignando pesos específicos en scikit-learn.\n\nPrimero, creemos un conjunto de datos desbalanceado y dividámoslo en conjuntos de entrenamiento y prueba.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n\n# Generamos un conjunto de datos desbalanceado\nX, y = make_classification(n_classes=2, class_sep=2,\n                           weights=[0.1, 0.90], n_informative=3, n_redundant=1, flip_y=0,\n                           n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n\n# Dividimos en conjunto de entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n```\n:::\n\n\nAhora, ajustaremos un modelo SVM considerando el desbalance mediante el uso de pesos de clase:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Definimos los pesos de las clases para tratar el desbalance\nweights = {0: 1000, 1: 1}  # Aumentamos el peso de la clase minoritaria\n\n# Creamos el clasificador SVM con los pesos de clase\nclf = SVC(kernel='linear', class_weight=weights)\n\n# Entrenamos el modelo\nclf.fit(X_train, y_train)\n\n# Evaluamos el modelo\naccuracy = clf.score(X_test, y_test)\nprint(f'Accuracy: {accuracy:.2f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 0.98\n```\n:::\n:::\n\n\n### Solución #2: Submuestreo y Sobremuestreo\n\nSi el algoritmo de aprendizaje no permite la ponderación de clases, existen técnicas de muestreo como el sobremuestreo (oversampling), el submuestreo (undersampling), y la creación de ejemplos sintéticos mediante algoritmos como SMOTE o ADASYN para equilibrar las clases.\n\nSMOTE (Synthetic Minority Over-sampling Technique) es una técnica de sobremuestreo que crea ejemplos sintéticos de la clase minoritaria para equilibrar el conjunto de datos. Veamos cómo aplicarlo usando la biblioteca `imbalanced-learn`.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import classification_report\n\n# Aplicamos SMOTE al conjunto de entrenamiento\nsmote = SMOTE(random_state=42)\nX_res, y_res = smote.fit_resample(X_train, y_train)\n\n# Entrenamos un nuevo clasificador SVM con los datos sobremuestreados\nclf_smote = SVC(kernel='linear')\nclf_smote.fit(X_res, y_res)\n\n# Evaluamos el modelo\ny_pred = clf_smote.predict(X_test)\nprint(classification_report(y_test, y_pred))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              precision    recall  f1-score   support\n\n           0       0.89      0.96      0.93        26\n           1       1.00      0.99      0.99       224\n\n    accuracy                           0.98       250\n   macro avg       0.94      0.97      0.96       250\nweighted avg       0.98      0.98      0.98       250\n\n```\n:::\n:::\n\n\nComparamos el efecto antes y después de aplicar SMOTE:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.coolwarm, edgecolors='k')\nplt.title('Antes de SMOTE')\n\nplt.subplot(1, 2, 2)\nplt.scatter(X_res[:, 0], X_res[:, 1], c=y_res, cmap=plt.cm.coolwarm, edgecolors='k')\nplt.title('Después de SMOTE')\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](7_practica_avanzada_files/figure-pdf/cell-5-output-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Combinación de Modelos \n\nLa combinación de modelos en el aprendizaje automático es una técnica poderosa que busca mejorar el rendimiento predictivo al integrar las fortalezas de varios modelos. Existen diversas formas de combinar modelos, siendo las más comunes el promedio (averaging), el voto de mayoría (majority vote) y el apilamiento (stacking). Cada uno de estos métodos tiene aplicaciones específicas y beneficios únicos.\n\n### Promedio (Averaging)\n\nEl método de promedio es aplicable tanto para la regresión como para la clasificación. Consiste en aplicar todos los modelos base al input \\(x\\) y luego promediar las predicciones. En clasificación, se promedian las probabilidades predichas para cada clase.\n\nConsideremos un conjunto de datos de regresión y combinemos las predicciones de varios modelos de regresión mediante el promedio.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Generamos un conjunto de datos de regresión\nX, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Entrenamos varios modelos\nmodel_rf = RandomForestRegressor(n_estimators=10, random_state=42).fit(X_train, y_train)\nmodel_gb = GradientBoostingRegressor(n_estimators=10, random_state=42).fit(X_train, y_train)\nmodel_lr = LinearRegression().fit(X_train, y_train)\n\n# Predecimos y promediamos las predicciones\npredictions = np.mean([model_rf.predict(X_test), model_gb.predict(X_test), model_lr.predict(X_test)], axis=0)\n\n# Evaluamos el rendimiento del modelo promedio\nfrom sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, predictions)\nmse_rf = mean_squared_error(y_test, model_rf.predict(X_test))\nmse_gb = mean_squared_error(y_test, model_gb.predict(X_test))\nmse_lr = mean_squared_error(y_test, model_lr.predict(X_test))\n\nprint(f'MSE del modelo RF: {mse_rf}')\nprint(f'MSE del modelo GB: {mse_gb}')\nprint(f'MSE del modelo LR: {mse_lr}')\nprint(f'MSE del modelo promediado: {mse}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMSE del modelo RF: 9445.970722326663\nMSE del modelo GB: 20390.298586678025\nMSE del modelo LR: 0.010704979443048707\nMSE del modelo promediado: 5842.696381684256\n```\n:::\n:::\n\n\n### Voto de mayoría (Majority Vote)\n\n\nEl voto de mayoría se utiliza para modelos de clasificación. Se aplica cada uno de los modelos base al input xx y se selecciona la clase que obtenga la mayoría de votos entre todas las predicciones.\n\nUtilizaremos varios clasificadores y combinaremos sus predicciones mediante el voto de mayoría.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\n\n# Generamos un conjunto de datos de clasificación\nX, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Entrenamos varios clasificadores\nmodel_rf = RandomForestClassifier(n_estimators=10, random_state=42)\nmodel_lr = LogisticRegression()\nmodel_svc = SVC(probability=True, random_state=42)\n\n# Combinamos mediante voto de mayoría\neclf = VotingClassifier(estimators=[('rf', model_rf), ('lr', model_lr), ('svc', model_svc)], voting='hard')\neclf.fit(X_train, y_train)\nmodel_rf.fit(X_train, y_train)\nmodel_lr.fit(X_train, y_train)\nmodel_svc.fit(X_train, y_train)\n\n\n# Evaluamos el rendimiento\naccuracy = eclf.score(X_test, y_test)\naccuracy_rf = model_rf.score(X_test, y_test)\naccuracy_lr = model_lr.score(X_test, y_test)    \naccuracy_svc = model_svc.score(X_test, y_test)\n\nprint(f'Accuracy del modelo RF: {accuracy_rf}')\nprint(f'Accuracy del modelo LR: {accuracy_lr}')\nprint(f'Accuracy del modelo SVC: {accuracy_svc}')\nprint(f'Accuracy del modelo combinado mediante voto de mayoría: {accuracy}')\n\ny_pred = eclf.predict(X_test)\nprint(classification_report(y_test, y_pred))\n\nprint(classification_report(y_test, model_rf.predict(X_test)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy del modelo RF: 0.8333333333333334\nAccuracy del modelo LR: 0.85\nAccuracy del modelo SVC: 0.8333333333333334\nAccuracy del modelo combinado mediante voto de mayoría: 0.8433333333333334\n              precision    recall  f1-score   support\n\n           0       0.81      0.88      0.84       145\n           1       0.88      0.81      0.84       155\n\n    accuracy                           0.84       300\n   macro avg       0.84      0.84      0.84       300\nweighted avg       0.85      0.84      0.84       300\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.88      0.84       145\n           1       0.88      0.79      0.83       155\n\n    accuracy                           0.83       300\n   macro avg       0.84      0.83      0.83       300\nweighted avg       0.84      0.83      0.83       300\n\n```\n:::\n:::\n\n\n###  Apilamiento (Stacking)\n\nEl apilamiento consiste en combinar varios modelos base y utilizar sus salidas como input para un meta-modelo, que hace la predicción final.\nEjemplo en Python para Stacking\n\nImplementaremos stacking con varios modelos base y un meta-modelo de regresión logística.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Definimos los modelos base y el meta-modelo\nbase_models = [('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n               ('svc', SVC(probability=True, random_state=42))]\nmeta_model = LogisticRegression()\n\n# Creamos el modelo de apilamiento\nstacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n\n# Entrenamos y evaluamos el modelo de apilamiento\nstacking_model.fit(X_train, y_train)\n\naccuracy = stacking_model.score(X_test, y_test)\nprint(f'Accuracy del modelo de apilamiento: {accuracy}')\n\nprint(classification_report(y_test, stacking_model.predict(X_test)))\nprint(classification_report(y_test, model_rf.predict(X_test)))\nprint(classification_report(y_test, model_svc.predict(X_test)))\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy del modelo de apilamiento: 0.84\n              precision    recall  f1-score   support\n\n           0       0.82      0.86      0.84       145\n           1       0.86      0.82      0.84       155\n\n    accuracy                           0.84       300\n   macro avg       0.84      0.84      0.84       300\nweighted avg       0.84      0.84      0.84       300\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.88      0.84       145\n           1       0.88      0.79      0.83       155\n\n    accuracy                           0.83       300\n   macro avg       0.84      0.83      0.83       300\nweighted avg       0.84      0.83      0.83       300\n\n              precision    recall  f1-score   support\n\n           0       0.81      0.86      0.83       145\n           1       0.86      0.81      0.83       155\n\n    accuracy                           0.83       300\n   macro avg       0.83      0.83      0.83       300\nweighted avg       0.83      0.83      0.83       300\n\n```\n:::\n:::\n\n\n## Entrenamiento de Redes Neuronales \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Crear un generador de datos con normalización\ndatagen = ImageDataGenerator(rescale=1./255)\n\n# Suponiendo que 'directorio_de_datos' es el camino a las imágenes\ntrain_generator = datagen.flow_from_directory(\n    directorio_de_datos,\n    target_size=(200, 200),  # Todas las imágenes se redimensionan a 200x200\n    batch_size=32,\n    class_mode='binary'  # o 'categorical' para clasificación multiclase\n)\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Crear un tokenizador para convertir palabras a índices\ntokenizer = Tokenizer(num_words=10000)  # Considera las 10,000 palabras más comunes\ntokenizer.fit_on_texts(textos)  # 'textos' es una lista de documentos de texto\n\n# Convertir textos en secuencias de índices\nsequences = tokenizer.texts_to_sequences(textos)\n\n# Acolchar secuencias para que tengan la misma longitud\ndata = pad_sequences(sequences, maxlen=100)  # Longitud fija de 100 para todas las secuencias\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\n# Crear un modelo simple como punto de partida\nmodel = Sequential([\n    Dense(64, activation='relu', input_shape=(100,)),  # Ejemplo para datos vectorizados de longitud 100\n    Dropout(0.5),  # Regularización mediante Dropout\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# Entrenar el modelo\nmodel.fit(data, etiquetas, epochs=10, validation_split=0.2)  # 'etiquetas' es un array de etiquetas\n```\n:::\n\n\n",
    "supporting": [
      "7_practica_avanzada_files/figure-pdf"
    ],
    "filters": []
  }
}